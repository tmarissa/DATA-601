{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET\n",
    "The dataset below has been explained in earlier notebooks and is being used here to carry on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraceptive_data = pd.read_csv(\"contraceptive_method_dataset.csv\", \n",
    "                                 encoding = \"ISO-8859-1\", engine='python')\n",
    "X = contraceptive_data.drop('children', axis=1).copy()\n",
    "contraceptive_data['predictor_population']= pd.cut(contraceptive_data['children'],\n",
    "                                       [-1,2,16], labels=[0,1])\n",
    "contraceptive_data['predictor_population_i']= contraceptive_data['predictor_population'].astype(int)\n",
    "y= contraceptive_data['predictor_population_i']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, \n",
    "                                                    random_state = 24, stratify = y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Scaler with Sklearn\n",
    "std_scaler = StandardScaler()\n",
    "#Training mean and std was calculated and was used in the transformation.\n",
    "std_scaler.fit(X_train)\n",
    "X_train_scaled = std_scaler.transform(X_train)\n",
    "## Never fit onto Test data!! Only Transform\n",
    "X_test_scaled  = std_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Modeling\n",
    "### Without Regularization (Vanilla Log Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate Logistic Regression with no penalty\n",
    "lr = LogisticRegression(penalty = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(penalty='none')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit Model and learned the coefficients\n",
    "lr.fit(X_train_scaled, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred is the estimated targets as returned by a classifier.\n",
    "y_pred = lr.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7769156159068865\n"
     ]
    }
   ],
   "source": [
    "#This is the accuracy of the trained data\n",
    "score = lr.score(X_train_scaled, y_train)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[324, 130],\n",
       "       [100, 477]], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create confusion matrix to evaluate the accuracy of the classification\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.753393665158371"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the accuracy of the test data\n",
    "lr.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "utils.plot_confusion_matrix(cm, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Notes_\n",
    "- For this Logistic Regression Model without Regularization. The Accuracy of the Test score is 0.7769 ~ 0.7769156159068865 while the Accuracy of the Train Score is  0.7534 ~ 0.753393665158371. Here is the Test Score is higher than the Train Score.\n",
    "- The Accuracy Score of this plot confusion matrix is approximately 0.7769 ~ 0.77691561590.\n",
    "- Of the no population increase (index 0) 454 which is 324 + 130, 324 (71.36%) is correctly classified. On the other hand the population increase (index 1) 577 which is 477 + 100, 477 (82.66897%) is correctly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "Using X train scaled and y train to do a cross validation for 5 split with no penalty, return train score and return estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    3.6s finished\n"
     ]
    }
   ],
   "source": [
    "#Using only trained data with 5 cross validation with return train score\n",
    "cv_fivefold = cross_validate(estimator= lr, \n",
    "                             X = X_train_scaled,\n",
    "                             y = y_train,\n",
    "                             cv = 5,\n",
    "                             n_jobs= -1, \n",
    "                             return_train_score= True, \n",
    "                             return_estimator= True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7826087 , 0.7815534 , 0.80582524, 0.72330097, 0.76699029])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Investigate the cv results. cv_fivefold is a directory because it has curly bracket\n",
    "cv_fivefold['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77427184, 0.77090909, 0.76727273, 0.78787879, 0.78181818])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cv_fivefold['train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_mean = cv_fivefold['test_score'].mean()\n",
    "\n",
    "validation_std = cv_fivefold['test_score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Logistic Regression 5-fold cv results (Accuracy) 0.772 +/- 0.027\n"
     ]
    }
   ],
   "source": [
    "print('Vanilla Logistic Regression 5-fold cv results (Accuracy) %.3f +/- %.3f'%(validation_mean, validation_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Notes_\n",
    "- The Vanilla Log Regression (Accuracy) without regularization is .772 +/- 0.027 which is almost the same as the accuracy of the test data which is 0.753393665158371."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic with Regularization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty = 'l2', C = 1, solver = 'saga', max_iter= 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, max_iter=1000, solver='saga')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[324, 130],\n",
       "       [100, 477]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "Using X train scaled and y train to do a cross validation for 5 split with return train score and return estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "cv_fivefold = cross_validate(estimator= lr, \n",
    "                             X = X_train_scaled,\n",
    "                             y = y_train,\n",
    "                             cv = 5,\n",
    "                             return_train_score= True, \n",
    "                             return_estimator= True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vanilla Regression 5-fold cv results (Accuracy) 0.772 =/- 0.027\n"
     ]
    }
   ],
   "source": [
    "validation_mean = cv_fivefold['test_score'].mean()\n",
    "\n",
    "validation_std = cv_fivefold['test_score'].std()\n",
    "\n",
    "print('Vanilla Regression 5-fold cv results (Accuracy) %.3f =/- %.3f'%(validation_mean, validation_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Notes_\n",
    "- The Logistic Regression Modeling without regularization has the same result in the vanilla regression 5-fold cv results. Its accuracy are both 77.2% +/- 0.027"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Validation with Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(C=1, max_iter=1000, solver='saga'),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']},\n",
       "             return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#Penalty of l2 is Ridge\n",
    "lr = LogisticRegression(penalty = 'l2', C = 1, solver = 'saga', max_iter= 1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prepare a grid with C and penalty. Next, Instantiate the grid search. Lastly, the fit the\n",
    "# grid search\n",
    "grid = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "grid_search_cv = GridSearchCV(estimator = lr, param_grid= grid, \n",
    "                              cv =5, return_train_score= True, verbose= 2)\n",
    "grid_search_cv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00313411, 0.0078649 , 0.00552802, 0.        , 0.00688934,\n",
       "        0.00625091, 0.00515261, 0.00826225, 0.00719495, 0.00619445]),\n",
       " 'std_fit_time': array([0.00626822, 0.00698872, 0.00686671, 0.        , 0.00786115,\n",
       "        0.00765577, 0.00654446, 0.00745809, 0.00146891, 0.00116457]),\n",
       " 'mean_score_time': array([0.00311704, 0.00019569, 0.        , 0.00624957, 0.00332484,\n",
       "        0.        , 0.00019989, 0.0006    , 0.00039992, 0.00080161]),\n",
       " 'std_score_time': array([0.00623407, 0.00039139, 0.        , 0.00765413, 0.00616145,\n",
       "        0.        , 0.00039978, 0.0004899 , 0.0004898 , 0.00040082]),\n",
       " 'param_C': masked_array(data=[0.01, 0.01, 0.1, 0.1, 1, 1, 10, 10, 100, 100],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1', 'l2', 'l1',\n",
       "                    'l2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 0.01, 'penalty': 'l1'},\n",
       "  {'C': 0.01, 'penalty': 'l2'},\n",
       "  {'C': 0.1, 'penalty': 'l1'},\n",
       "  {'C': 0.1, 'penalty': 'l2'},\n",
       "  {'C': 1, 'penalty': 'l1'},\n",
       "  {'C': 1, 'penalty': 'l2'},\n",
       "  {'C': 10, 'penalty': 'l1'},\n",
       "  {'C': 10, 'penalty': 'l2'},\n",
       "  {'C': 100, 'penalty': 'l1'},\n",
       "  {'C': 100, 'penalty': 'l2'}],\n",
       " 'split0_test_score': array([0.74396135, 0.7826087 , 0.77294686, 0.7826087 , 0.7826087 ,\n",
       "        0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 , 0.7826087 ]),\n",
       " 'split1_test_score': array([0.73786408, 0.79126214, 0.77669903, 0.7815534 , 0.78640777,\n",
       "        0.7815534 , 0.78640777, 0.7815534 , 0.78640777, 0.7815534 ]),\n",
       " 'split2_test_score': array([0.76213592, 0.80097087, 0.80582524, 0.81067961, 0.80582524,\n",
       "        0.80582524, 0.80582524, 0.80582524, 0.80582524, 0.80582524]),\n",
       " 'split3_test_score': array([0.7184466 , 0.72815534, 0.73300971, 0.73300971, 0.73300971,\n",
       "        0.72330097, 0.72330097, 0.72330097, 0.72330097, 0.72330097]),\n",
       " 'split4_test_score': array([0.73300971, 0.76699029, 0.76213592, 0.76699029, 0.76699029,\n",
       "        0.76699029, 0.76699029, 0.76699029, 0.76699029, 0.76699029]),\n",
       " 'mean_test_score': array([0.73908353, 0.77399747, 0.77012335, 0.77496834, 0.77496834,\n",
       "        0.77205572, 0.77302659, 0.77205572, 0.77302659, 0.77205572]),\n",
       " 'std_test_score': array([0.01427913, 0.02549662, 0.0235247 , 0.025303  , 0.02435389,\n",
       "        0.02736653, 0.0277694 , 0.02736653, 0.0277694 , 0.02736653]),\n",
       " 'rank_test_score': array([10,  3,  9,  1,  1,  6,  4,  6,  4,  6]),\n",
       " 'split0_train_score': array([0.74150485, 0.77305825, 0.78398058, 0.77548544, 0.77548544,\n",
       "        0.77427184, 0.77427184, 0.77427184, 0.77427184, 0.77427184]),\n",
       " 'split1_train_score': array([0.7430303 , 0.77575758, 0.77212121, 0.77818182, 0.77575758,\n",
       "        0.77333333, 0.77333333, 0.77090909, 0.77090909, 0.77090909]),\n",
       " 'split2_train_score': array([0.72      , 0.76484848, 0.77333333, 0.76484848, 0.76727273,\n",
       "        0.76606061, 0.76727273, 0.76727273, 0.76727273, 0.76727273]),\n",
       " 'split3_train_score': array([0.74787879, 0.78909091, 0.7830303 , 0.7830303 , 0.78545455,\n",
       "        0.78666667, 0.78787879, 0.78787879, 0.78787879, 0.78787879]),\n",
       " 'split4_train_score': array([0.74424242, 0.78181818, 0.77454545, 0.7830303 , 0.78060606,\n",
       "        0.7830303 , 0.78181818, 0.78181818, 0.78181818, 0.78181818]),\n",
       " 'mean_train_score': array([0.73933127, 0.77691468, 0.77740218, 0.77691527, 0.77691527,\n",
       "        0.77667255, 0.77691497, 0.77643013, 0.77643013, 0.77643013]),\n",
       " 'std_train_score': array([0.00989227, 0.00817446, 0.00505086, 0.00669392, 0.00604821,\n",
       "        0.00734616, 0.00716985, 0.00747129, 0.00747129, 0.00747129])}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the grid search cv results. Then make the dataframe\n",
    "grid_search_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>5</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean_fit_time</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00688934</td>\n",
       "      <td>0.0078649</td>\n",
       "      <td>0.00515261</td>\n",
       "      <td>0.00719495</td>\n",
       "      <td>0.00625091</td>\n",
       "      <td>0.00826225</td>\n",
       "      <td>0.00619445</td>\n",
       "      <td>0.00552802</td>\n",
       "      <td>0.00313411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_fit_time</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00786115</td>\n",
       "      <td>0.00698872</td>\n",
       "      <td>0.00654446</td>\n",
       "      <td>0.00146891</td>\n",
       "      <td>0.00765577</td>\n",
       "      <td>0.00745809</td>\n",
       "      <td>0.00116457</td>\n",
       "      <td>0.00686671</td>\n",
       "      <td>0.00626822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_score_time</th>\n",
       "      <td>0.00624957</td>\n",
       "      <td>0.00332484</td>\n",
       "      <td>0.000195694</td>\n",
       "      <td>0.00019989</td>\n",
       "      <td>0.000399923</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000600004</td>\n",
       "      <td>0.000801611</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00311704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_score_time</th>\n",
       "      <td>0.00765413</td>\n",
       "      <td>0.00616145</td>\n",
       "      <td>0.000391388</td>\n",
       "      <td>0.00039978</td>\n",
       "      <td>0.000489804</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000489901</td>\n",
       "      <td>0.000400822</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00623407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_C</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param_penalty</th>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l1</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l2</td>\n",
       "      <td>l1</td>\n",
       "      <td>l1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 1, 'penalty': 'l1'}</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 10, 'penalty': 'l1'}</td>\n",
       "      <td>{'C': 100, 'penalty': 'l1'}</td>\n",
       "      <td>{'C': 1, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 100, 'penalty': 'l2'}</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l1'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_test_score</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.772947</td>\n",
       "      <td>0.743961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_test_score</th>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.791262</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.737864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_test_score</th>\n",
       "      <td>0.81068</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.800971</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.762136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_test_score</th>\n",
       "      <td>0.73301</td>\n",
       "      <td>0.73301</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.723301</td>\n",
       "      <td>0.723301</td>\n",
       "      <td>0.723301</td>\n",
       "      <td>0.723301</td>\n",
       "      <td>0.723301</td>\n",
       "      <td>0.73301</td>\n",
       "      <td>0.718447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_test_score</th>\n",
       "      <td>0.76699</td>\n",
       "      <td>0.76699</td>\n",
       "      <td>0.76699</td>\n",
       "      <td>0.76699</td>\n",
       "      <td>0.76699</td>\n",
       "      <td>0.76699</td>\n",
       "      <td>0.76699</td>\n",
       "      <td>0.76699</td>\n",
       "      <td>0.762136</td>\n",
       "      <td>0.73301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_test_score</th>\n",
       "      <td>0.774968</td>\n",
       "      <td>0.774968</td>\n",
       "      <td>0.773997</td>\n",
       "      <td>0.773027</td>\n",
       "      <td>0.773027</td>\n",
       "      <td>0.772056</td>\n",
       "      <td>0.772056</td>\n",
       "      <td>0.772056</td>\n",
       "      <td>0.770123</td>\n",
       "      <td>0.739084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_test_score</th>\n",
       "      <td>0.025303</td>\n",
       "      <td>0.0243539</td>\n",
       "      <td>0.0254966</td>\n",
       "      <td>0.0277694</td>\n",
       "      <td>0.0277694</td>\n",
       "      <td>0.0273665</td>\n",
       "      <td>0.0273665</td>\n",
       "      <td>0.0273665</td>\n",
       "      <td>0.0235247</td>\n",
       "      <td>0.0142791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rank_test_score</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split0_train_score</th>\n",
       "      <td>0.775485</td>\n",
       "      <td>0.775485</td>\n",
       "      <td>0.773058</td>\n",
       "      <td>0.774272</td>\n",
       "      <td>0.774272</td>\n",
       "      <td>0.774272</td>\n",
       "      <td>0.774272</td>\n",
       "      <td>0.774272</td>\n",
       "      <td>0.783981</td>\n",
       "      <td>0.741505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split1_train_score</th>\n",
       "      <td>0.778182</td>\n",
       "      <td>0.775758</td>\n",
       "      <td>0.775758</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.770909</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.770909</td>\n",
       "      <td>0.770909</td>\n",
       "      <td>0.772121</td>\n",
       "      <td>0.74303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split2_train_score</th>\n",
       "      <td>0.764848</td>\n",
       "      <td>0.767273</td>\n",
       "      <td>0.764848</td>\n",
       "      <td>0.767273</td>\n",
       "      <td>0.767273</td>\n",
       "      <td>0.766061</td>\n",
       "      <td>0.767273</td>\n",
       "      <td>0.767273</td>\n",
       "      <td>0.773333</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split3_train_score</th>\n",
       "      <td>0.78303</td>\n",
       "      <td>0.785455</td>\n",
       "      <td>0.789091</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.78303</td>\n",
       "      <td>0.747879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>split4_train_score</th>\n",
       "      <td>0.78303</td>\n",
       "      <td>0.780606</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.78303</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.774545</td>\n",
       "      <td>0.744242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_train_score</th>\n",
       "      <td>0.776915</td>\n",
       "      <td>0.776915</td>\n",
       "      <td>0.776915</td>\n",
       "      <td>0.776915</td>\n",
       "      <td>0.77643</td>\n",
       "      <td>0.776673</td>\n",
       "      <td>0.77643</td>\n",
       "      <td>0.77643</td>\n",
       "      <td>0.777402</td>\n",
       "      <td>0.739331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_train_score</th>\n",
       "      <td>0.00669392</td>\n",
       "      <td>0.00604821</td>\n",
       "      <td>0.00817446</td>\n",
       "      <td>0.00716985</td>\n",
       "      <td>0.00747129</td>\n",
       "      <td>0.00734616</td>\n",
       "      <td>0.00747129</td>\n",
       "      <td>0.00747129</td>\n",
       "      <td>0.00505086</td>\n",
       "      <td>0.00989227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              3                          4  \\\n",
       "mean_fit_time                                 0                 0.00688934   \n",
       "std_fit_time                                  0                 0.00786115   \n",
       "mean_score_time                      0.00624957                 0.00332484   \n",
       "std_score_time                       0.00765413                 0.00616145   \n",
       "param_C                                     0.1                          1   \n",
       "param_penalty                                l2                         l1   \n",
       "params              {'C': 0.1, 'penalty': 'l2'}  {'C': 1, 'penalty': 'l1'}   \n",
       "split0_test_score                      0.782609                   0.782609   \n",
       "split1_test_score                      0.781553                   0.786408   \n",
       "split2_test_score                       0.81068                   0.805825   \n",
       "split3_test_score                       0.73301                    0.73301   \n",
       "split4_test_score                       0.76699                    0.76699   \n",
       "mean_test_score                        0.774968                   0.774968   \n",
       "std_test_score                         0.025303                  0.0243539   \n",
       "rank_test_score                               1                          1   \n",
       "split0_train_score                     0.775485                   0.775485   \n",
       "split1_train_score                     0.778182                   0.775758   \n",
       "split2_train_score                     0.764848                   0.767273   \n",
       "split3_train_score                      0.78303                   0.785455   \n",
       "split4_train_score                      0.78303                   0.780606   \n",
       "mean_train_score                       0.776915                   0.776915   \n",
       "std_train_score                      0.00669392                 0.00604821   \n",
       "\n",
       "                                               1                           6  \\\n",
       "mean_fit_time                          0.0078649                  0.00515261   \n",
       "std_fit_time                          0.00698872                  0.00654446   \n",
       "mean_score_time                      0.000195694                  0.00019989   \n",
       "std_score_time                       0.000391388                  0.00039978   \n",
       "param_C                                     0.01                          10   \n",
       "param_penalty                                 l2                          l1   \n",
       "params              {'C': 0.01, 'penalty': 'l2'}  {'C': 10, 'penalty': 'l1'}   \n",
       "split0_test_score                       0.782609                    0.782609   \n",
       "split1_test_score                       0.791262                    0.786408   \n",
       "split2_test_score                       0.800971                    0.805825   \n",
       "split3_test_score                       0.728155                    0.723301   \n",
       "split4_test_score                        0.76699                     0.76699   \n",
       "mean_test_score                         0.773997                    0.773027   \n",
       "std_test_score                         0.0254966                   0.0277694   \n",
       "rank_test_score                                3                           4   \n",
       "split0_train_score                      0.773058                    0.774272   \n",
       "split1_train_score                      0.775758                    0.773333   \n",
       "split2_train_score                      0.764848                    0.767273   \n",
       "split3_train_score                      0.789091                    0.787879   \n",
       "split4_train_score                      0.781818                    0.781818   \n",
       "mean_train_score                        0.776915                    0.776915   \n",
       "std_train_score                       0.00817446                  0.00716985   \n",
       "\n",
       "                                              8                          5  \\\n",
       "mean_fit_time                        0.00719495                 0.00625091   \n",
       "std_fit_time                         0.00146891                 0.00765577   \n",
       "mean_score_time                     0.000399923                          0   \n",
       "std_score_time                      0.000489804                          0   \n",
       "param_C                                     100                          1   \n",
       "param_penalty                                l1                         l2   \n",
       "params              {'C': 100, 'penalty': 'l1'}  {'C': 1, 'penalty': 'l2'}   \n",
       "split0_test_score                      0.782609                   0.782609   \n",
       "split1_test_score                      0.786408                   0.781553   \n",
       "split2_test_score                      0.805825                   0.805825   \n",
       "split3_test_score                      0.723301                   0.723301   \n",
       "split4_test_score                       0.76699                    0.76699   \n",
       "mean_test_score                        0.773027                   0.772056   \n",
       "std_test_score                        0.0277694                  0.0273665   \n",
       "rank_test_score                               4                          6   \n",
       "split0_train_score                     0.774272                   0.774272   \n",
       "split1_train_score                     0.770909                   0.773333   \n",
       "split2_train_score                     0.767273                   0.766061   \n",
       "split3_train_score                     0.787879                   0.786667   \n",
       "split4_train_score                     0.781818                    0.78303   \n",
       "mean_train_score                        0.77643                   0.776673   \n",
       "std_train_score                      0.00747129                 0.00734616   \n",
       "\n",
       "                                             7                            9  \\\n",
       "mean_fit_time                       0.00826225                   0.00619445   \n",
       "std_fit_time                        0.00745809                   0.00116457   \n",
       "mean_score_time                    0.000600004                  0.000801611   \n",
       "std_score_time                     0.000489901                  0.000400822   \n",
       "param_C                                     10                          100   \n",
       "param_penalty                               l2                           l2   \n",
       "params              {'C': 10, 'penalty': 'l2'}  {'C': 100, 'penalty': 'l2'}   \n",
       "split0_test_score                     0.782609                     0.782609   \n",
       "split1_test_score                     0.781553                     0.781553   \n",
       "split2_test_score                     0.805825                     0.805825   \n",
       "split3_test_score                     0.723301                     0.723301   \n",
       "split4_test_score                      0.76699                      0.76699   \n",
       "mean_test_score                       0.772056                     0.772056   \n",
       "std_test_score                       0.0273665                    0.0273665   \n",
       "rank_test_score                              6                            6   \n",
       "split0_train_score                    0.774272                     0.774272   \n",
       "split1_train_score                    0.770909                     0.770909   \n",
       "split2_train_score                    0.767273                     0.767273   \n",
       "split3_train_score                    0.787879                     0.787879   \n",
       "split4_train_score                    0.781818                     0.781818   \n",
       "mean_train_score                       0.77643                      0.77643   \n",
       "std_train_score                     0.00747129                   0.00747129   \n",
       "\n",
       "                                              2                             0  \n",
       "mean_fit_time                        0.00552802                    0.00313411  \n",
       "std_fit_time                         0.00686671                    0.00626822  \n",
       "mean_score_time                               0                    0.00311704  \n",
       "std_score_time                                0                    0.00623407  \n",
       "param_C                                     0.1                          0.01  \n",
       "param_penalty                                l1                            l1  \n",
       "params              {'C': 0.1, 'penalty': 'l1'}  {'C': 0.01, 'penalty': 'l1'}  \n",
       "split0_test_score                      0.772947                      0.743961  \n",
       "split1_test_score                      0.776699                      0.737864  \n",
       "split2_test_score                      0.805825                      0.762136  \n",
       "split3_test_score                       0.73301                      0.718447  \n",
       "split4_test_score                      0.762136                       0.73301  \n",
       "mean_test_score                        0.770123                      0.739084  \n",
       "std_test_score                        0.0235247                     0.0142791  \n",
       "rank_test_score                               9                            10  \n",
       "split0_train_score                     0.783981                      0.741505  \n",
       "split1_train_score                     0.772121                       0.74303  \n",
       "split2_train_score                     0.773333                          0.72  \n",
       "split3_train_score                      0.78303                      0.747879  \n",
       "split4_train_score                     0.774545                      0.744242  \n",
       "mean_train_score                       0.777402                      0.739331  \n",
       "std_train_score                      0.00505086                    0.00989227  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search_cv.cv_results_ ).sort_values('mean_test_score', ascending = False).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cross Validation in 5 Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "# Print the best parameters and cross validate the best estimator, penalty is ridge l2\n",
    "lr = LogisticRegression(C = 0.1, penalty = 'l2', solver = 'saga', max_iter= 10000)\n",
    "cv_fivefold = cross_validate(estimator= lr, \n",
    "                             X = X_train_scaled,\n",
    "                             y = y_train,\n",
    "                             cv = 5,\n",
    "                             return_train_score= True, \n",
    "                             return_estimator= True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7826087 , 0.7815534 , 0.81067961, 0.73300971, 0.76699029])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_fivefold['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Log Regression (Ridge) 5-fold cv results (Accuracy) 0.775 +/- 0.025\n"
     ]
    }
   ],
   "source": [
    "## fit best regularization logreg and plot the confusion matrix\n",
    "validation_mean = cv_fivefold['test_score'].mean()\n",
    "\n",
    "validation_std = cv_fivefold['test_score'].std()\n",
    "\n",
    "print('Regularized Log Regression (Ridge) 5-fold cv results (Accuracy) %.3f +/- %.3f'%(validation_mean, validation_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note_\n",
    "- Regularized Log Regression (Ridge) 5 fold cv results (Accuracy) 0.775 +/- 0.025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Validation with Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.0s\n",
      "[CV] C=0.01, penalty=l1 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l1, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.0s\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] ............................... C=0.01, penalty=l2, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.0s\n",
      "[CV] C=0.1, penalty=l1 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l1, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.0s\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[CV] ................................ C=0.1, penalty=l2, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s\n",
      "[CV] C=1, penalty=l1 .................................................\n",
      "[CV] .................................. C=1, penalty=l1, total=   0.0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.0s\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[CV] .................................. C=1, penalty=l2, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l1 ................................................\n",
      "[CV] ................................. C=10, penalty=l1, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.0s\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[CV] ................................. C=10, penalty=l2, total=   0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.0s\n",
      "[CV] C=100, penalty=l1 ...............................................\n",
      "[CV] ................................ C=100, penalty=l1, total=   0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.0s\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[CV] ................................ C=100, penalty=l2, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=LogisticRegression(C=1, max_iter=1000, penalty='l1',\n",
       "                                          solver='saga'),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']},\n",
       "             return_train_score=True, verbose=2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search\n",
    "lr = LogisticRegression(penalty = 'l1', C = 1, solver = 'saga', max_iter= 1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prepare a grid with C and penalty. Next, Instantiate the grid search. Lastly, the fit the\n",
    "# grid search\n",
    "grid = {'C': [0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
    "grid_search_cv = GridSearchCV(estimator = lr, param_grid= grid, \n",
    "                              cv =5, return_train_score= True, verbose= 2)\n",
    "grid_search_cv.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ................................................. , total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(C = 0.1, penalty = 'l1', solver = 'saga', max_iter= 10000)\n",
    "cv_fivefold = cross_validate(estimator= lr, \n",
    "                             X = X_train_scaled,\n",
    "                             y = y_train,\n",
    "                             cv = 5,\n",
    "                             return_train_score= True, \n",
    "                             return_estimator= True, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regularized Log Regression (Lasso) 5-fold cv results (Accuracy) 0.770 +/- 0.024\n"
     ]
    }
   ],
   "source": [
    "## fit best regularization logreg and plot the confusion matrix\n",
    "validation_mean = cv_fivefold['test_score'].mean()\n",
    "\n",
    "validation_std = cv_fivefold['test_score'].std()\n",
    "print('Regularized Log Regression (Lasso) 5-fold cv results (Accuracy) %.3f +/- %.3f'%(validation_mean, validation_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
